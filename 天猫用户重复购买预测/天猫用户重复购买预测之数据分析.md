# èµ›é¢˜ç†è§£
[èµ›é¢˜é“¾æ¥](https://tianchi.aliyun.com/competition/entrance/231576/introduction)  
**èµ›é¢˜èƒŒæ™¯**ï¼š  
å•†å®¶æœ‰æ—¶ä¼šåœ¨ç‰¹å®šæ—¥æœŸï¼Œä¾‹å¦‚Boxing-dayï¼Œé»‘è‰²æ˜ŸæœŸäº”æˆ–æ˜¯åŒåä¸€ï¼ˆ11æœˆ11æ—¥ï¼‰å¼€å±•å¤§å‹ä¿ƒé”€æ´»åŠ¨æˆ–è€…å‘æ”¾ä¼˜æƒ åˆ¸ä»¥å¸å¼•æ¶ˆè´¹è€…ï¼Œç„¶è€Œå¾ˆå¤šè¢«å¸å¼•æ¥çš„ä¹°å®¶éƒ½æ˜¯ä¸€æ¬¡æ€§æ¶ˆè´¹è€…ï¼Œè¿™äº›ä¿ƒé”€æ´»åŠ¨å¯èƒ½å¯¹é”€å”®ä¸šç»©çš„å¢é•¿å¹¶æ²¡æœ‰é•¿è¿œå¸®åŠ©ï¼Œå› æ­¤ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå•†å®¶éœ€è¦è¯†åˆ«å‡ºå“ªç±»æ¶ˆè´¹è€…å¯ä»¥è½¬åŒ–ä¸ºé‡å¤è´­ä¹°è€…ã€‚é€šè¿‡å¯¹è¿™äº›æ½œåœ¨çš„å¿ è¯šå®¢æˆ·è¿›è¡Œå®šä½ï¼Œå•†å®¶å¯ä»¥å¤§å¤§é™ä½ä¿ƒé”€æˆæœ¬ï¼Œæé«˜æŠ•èµ„å›æŠ¥ç‡ï¼ˆReturn on Investment, ROIï¼‰ã€‚ä¼—æ‰€å‘¨çŸ¥çš„æ˜¯ï¼Œåœ¨çº¿æŠ•æ”¾å¹¿å‘Šæ—¶ç²¾å‡†å®šä½å®¢æˆ·æ˜¯ä»¶æ¯”è¾ƒéš¾çš„äº‹æƒ…ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹æ–°æ¶ˆè´¹è€…çš„å®šä½ã€‚ä¸è¿‡ï¼Œåˆ©ç”¨å¤©çŒ«é•¿æœŸç§¯ç´¯çš„ç”¨æˆ·è¡Œä¸ºæ—¥å¿—ï¼Œæˆ‘ä»¬æˆ–è®¸å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚  
æˆ‘ä»¬æä¾›äº†ä¸€äº›å•†å®¶ä¿¡æ¯ï¼Œä»¥åŠåœ¨â€œåŒåä¸€â€æœŸé—´è´­ä¹°äº†å¯¹åº”äº§å“çš„æ–°æ¶ˆè´¹è€…ä¿¡æ¯ã€‚ä½ çš„ä»»åŠ¡æ˜¯é¢„æµ‹ç»™å®šçš„å•†å®¶ä¸­ï¼Œå“ªäº›æ–°æ¶ˆè´¹è€…åœ¨æœªæ¥ä¼šæˆä¸ºå¿ å®å®¢æˆ·ï¼Œå³éœ€è¦é¢„æµ‹è¿™äº›æ–°æ¶ˆè´¹è€…åœ¨6ä¸ªæœˆå†…å†æ¬¡è´­ä¹°çš„æ¦‚ç‡ã€‚    
**æ•°æ®è¯´æ˜**ï¼š  
æ•°æ®é›†ä¸»è¦åŒ…æ‹¬åœ¨â€åŒåä¸€â€œä¹‹å‰å’Œä¹‹åçš„å…­ä¸ªæœˆå†…ï¼ŒåŒ¿åç”¨æˆ·è´­ä¹°çš„è¡Œä¸ºæ—¥å¿—æ•°æ®ï¼Œç”¨æˆ·çš„ç”»åƒæ•°æ®ï¼Œä»¥åŠç›¸å…³çš„æŒ‡ç¤ºæ ‡ç­¾ï¼Œæ ‡æ˜å…¶æ˜¯å¦ä¸ºé‡å¤è´­ä¹°ç”¨æˆ·ã€‚  

- ç”¨æˆ·è¡Œä¸ºæ—¥å¿—

|  å­—æ®µåç§°   |                             æè¿°                             |
| :---------: | :----------------------------------------------------------: |
|   user_id   |                      è´­ç‰©è€…çš„å”¯ä¸€IDç¼–ç                       |
|   item_id   |                      è´­ç‰©è€…çš„å”¯ä¸€IDç¼–ç                       |
|   cat_id    |                    å•†å“æ‰€å±å“ç±»çš„å”¯ä¸€ç¼–ç                     |
| merchant_id |                       å•†å®¶çš„å”¯ä¸€IDç¼–ç                        |
|  brand_id   |                      å•†å“å“ç‰Œçš„å”¯ä¸€ç¼–ç                       |
|  time_tamp  |                    è´­ä¹°æ—¶é—´ï¼ˆæ ¼å¼ï¼šmmddï¼‰                    |
| action_type | åŒ…å«{0, 1, 2, 3}ï¼Œ0è¡¨ç¤ºå•å‡»ï¼Œ1è¡¨ç¤ºæ·»åŠ åˆ°è´­ç‰©è½¦ï¼Œ2è¡¨ç¤ºè´­ä¹°ï¼Œ3è¡¨ç¤ºæ·»åŠ åˆ°æ”¶è—å¤¹ |

- ç”¨æˆ·ç”»åƒ

| å­—æ®µåç§°  |                             æè¿°                             |
| :-------: | :----------------------------------------------------------: |
|  user_id  |                      è´­ç‰©è€…çš„å”¯ä¸€IDç¼–ç                       |
| age_range | ç”¨æˆ·å¹´é¾„èŒƒå›´ã€‚<18å²ä¸º1ï¼›[18,24]ä¸º2ï¼› [25,29]ä¸º3ï¼› [30,34]ä¸º4ï¼›[35,39]ä¸º5ï¼›[40,49]ä¸º6ï¼› > = 50æ—¶ä¸º7å’Œ8; 0å’ŒNULLè¡¨ç¤ºæœªçŸ¥ |
|  gender   |       ç”¨æˆ·æ€§åˆ«ã€‚0è¡¨ç¤ºå¥³æ€§ï¼Œ1è¡¨ç¤ºç”·æ€§ï¼Œ2å’ŒNULLè¡¨ç¤ºæœªçŸ¥        |

- è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®

| å­—æ®µåç§°    |                             æè¿°                             |
| ----------- | :----------------------------------------------------------: |
| user_id     |                      è´­ç‰©è€…çš„å”¯ä¸€IDç¼–ç                       |
| merchant_id |                       å•†å®¶çš„å”¯ä¸€IDç¼–ç                        |
| label       | åŒ…å«{0, 1}ï¼Œ1è¡¨ç¤ºé‡å¤ä¹°å®¶ï¼Œ0è¡¨ç¤ºéé‡å¤ä¹°å®¶ã€‚æµ‹è¯•é›†è¿™ä¸€éƒ¨åˆ†éœ€è¦é¢„æµ‹ï¼Œå› æ­¤ä¸ºç©ºã€‚ |


**è¯„ä»·æŒ‡æ ‡**ï¼š  
$$
AUC = \cfrac{\sum_{i\in{positive Class}}rank_{i} - \cfrac{M(1+M)}{2}}{M*N}
$$
å…¶ä¸­ï¼ŒMè¡¨ç¤ºæ­£æ ·æœ¬ä¸ªæ•°ï¼ŒNè¡¨ç¤ºè´Ÿæ ·æœ¬ä¸ªæ•°ï¼ŒAUCåæ˜ äº†<font color = "red">æ¨¡å‹å¯¹æ­£è´Ÿæ ·æœ¬æ’åºèƒ½åŠ›çš„å¼ºå¼±</font>ï¼Œå¯¹Scoreçš„å¤§å°å’Œç²¾åº¦æ²¡æœ‰è¦æ±‚ã€‚  
**è§£é¢˜æ€è·¯ï¼š**  
![](./imgs/è§£é¢˜æ€è·¯.png)  


# EDA


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time
import scipy
import gc
from collections import Counter
import warnings
from matplotlib import rcParams

config = {
    "font.family":'Times New Roman',  # è®¾ç½®å­—ä½“ç±»å‹
}

rcParams.update(config)
warnings.filterwarnings(action="ignore")

%matplotlib inline
```


```python
# æ•°æ®å­˜å‚¨æƒ…å†µ
!tree data/data_format1/
```

    [01;34mdata/data_format1/[00m
    â”œâ”€â”€ test_format1.csv
    â”œâ”€â”€ train_format1.csv
    â”œâ”€â”€ user_info_format1.csv
    â””â”€â”€ user_log_format1.csv
    
    0 directories, 4 files

```python
# é—®é¢˜ï¼šå¦‚ä½•ä¼˜åŒ–è¯»å…¥æ•°æ®çš„å†…å­˜å ç”¨æƒ…å†µï¼Ÿ

# è§£é‡Šå†…å­˜
def reduce_mem(df):
    """å¯¹äºæ•°å€¼ç±»å‹çš„æ•°æ®è¿›è¡Œå†…å­˜èŠ‚çœ"""
    
    starttime = time.time()
    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
    start_mem = df.memory_usage().sum() / 1024**2  # ç»Ÿè®¡å†…å­˜ä½¿ç”¨æƒ…å†µ
    
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if pd.isnull(c_min) or pd.isnull(c_max):
                continue
            if str(col_type)[:3] == 'int':
                # è£…æ¢æ•°æ®ç±»å‹
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
                    
    end_mem = df.memory_usage().sum() / 1024**2
    print('-- Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction),time spend:{:2.2f} min'.format(end_mem,
                                                                                                           100*(start_mem-end_mem)/start_mem,
                                                                                                           (time.time()-starttime)/60))
    return df
```

## è®­ç»ƒé›†


```python
train_data = reduce_mem(pd.read_csv("./data/data_format1/train_format1.csv"))
train_data
```

    -- Mem. usage decreased to  1.74 Mb (70.8% reduction),time spend:0.00 min

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>merchant_id</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>34176</td>
      <td>3906</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>34176</td>
      <td>121</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>34176</td>
      <td>4356</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>34176</td>
      <td>2217</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>230784</td>
      <td>4818</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>260859</th>
      <td>359807</td>
      <td>4325</td>
      <td>0</td>
    </tr>
    <tr>
      <th>260860</th>
      <td>294527</td>
      <td>3971</td>
      <td>0</td>
    </tr>
    <tr>
      <th>260861</th>
      <td>294527</td>
      <td>152</td>
      <td>0</td>
    </tr>
    <tr>
      <th>260862</th>
      <td>294527</td>
      <td>2537</td>
      <td>0</td>
    </tr>
    <tr>
      <th>260863</th>
      <td>229247</td>
      <td>4140</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>260864 rows Ã— 3 columns</p>

```python
train_data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 260864 entries, 0 to 260863
    Data columns (total 3 columns):
     #   Column       Non-Null Count   Dtype
    ---  ------       --------------   -----
     0   user_id      260864 non-null  int32
     1   merchant_id  260864 non-null  int16
     2   label        260864 non-null  int8 
    dtypes: int16(1), int32(1), int8(1)
    memory usage: 1.7 MB

```python
train_data.nunique()
```


    user_id        212062
    merchant_id      1993
    label               2
    dtype: int64

## ç”¨æˆ·ä¿¡æ¯è¡¨


```python
user_info = reduce_mem(pd.read_csv("./data/data_format1/user_info_format1.csv"))
user_info
```

    -- Mem. usage decreased to  3.24 Mb (66.7% reduction),time spend:0.00 min

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>age_range</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>376517</td>
      <td>6.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>234512</td>
      <td>5.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>344532</td>
      <td>5.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>186135</td>
      <td>5.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>30230</td>
      <td>5.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>424165</th>
      <td>395814</td>
      <td>3.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>424166</th>
      <td>245950</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>424167</th>
      <td>208016</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>424168</th>
      <td>272535</td>
      <td>6.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>424169</th>
      <td>18031</td>
      <td>3.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>424170 rows Ã— 3 columns</p>

```python
user_info.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 424170 entries, 0 to 424169
    Data columns (total 3 columns):
     #   Column     Non-Null Count   Dtype  
    ---  ------     --------------   -----  
     0   user_id    424170 non-null  int32  
     1   age_range  421953 non-null  float16
     2   gender     417734 non-null  float16
    dtypes: float16(2), int32(1)
    memory usage: 3.2 MB

```python
user_info.nunique()
```


    user_id      424170
    age_range         9
    gender            3
    dtype: int64

## ç”¨æˆ·è¡Œä¸ºæ•°æ®


```python
# é—®é¢˜ï¼šå¦‚ä½•åœ¨pandasè¯»å–å¤§æ‰¹é‡çš„æ•°æ®?

# æ•°æ®é‡è¿‡å¤§ï¼Œé‡‡ç”¨è¿­ä»£æ–¹æ³•
reader = pd.read_csv("./data/data_format1/user_log_format1.csv", iterator=True)
# try:
#     df = reader.get_chunk(100000)
# except StopIteration:
#     print("Iteration is stopped.")
loop = True
chunkSize = 100000
chunks = []

while loop:
    try:
        chunk = reader.get_chunk(chunkSize)
        chunks.append(chunk)
    except StopIteration:
        loop = False
        print("Iteration is stopped.")
        
df = pd.concat(chunks, ignore_index=True)
```

```python
user_log = reduce_mem(df)
user_log
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>item_id</th>
      <th>cat_id</th>
      <th>seller_id</th>
      <th>brand_id</th>
      <th>time_stamp</th>
      <th>action_type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>328862</td>
      <td>323294</td>
      <td>833</td>
      <td>2882</td>
      <td>2660.0</td>
      <td>829</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>328862</td>
      <td>844400</td>
      <td>1271</td>
      <td>2882</td>
      <td>2660.0</td>
      <td>829</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>328862</td>
      <td>575153</td>
      <td>1271</td>
      <td>2882</td>
      <td>2660.0</td>
      <td>829</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>328862</td>
      <td>996875</td>
      <td>1271</td>
      <td>2882</td>
      <td>2660.0</td>
      <td>829</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>328862</td>
      <td>1086186</td>
      <td>1271</td>
      <td>1253</td>
      <td>1049.0</td>
      <td>829</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>54925325</th>
      <td>208016</td>
      <td>107662</td>
      <td>898</td>
      <td>1346</td>
      <td>7996.0</td>
      <td>1110</td>
      <td>0</td>
    </tr>
    <tr>
      <th>54925326</th>
      <td>208016</td>
      <td>1058313</td>
      <td>898</td>
      <td>1346</td>
      <td>7996.0</td>
      <td>1110</td>
      <td>0</td>
    </tr>
    <tr>
      <th>54925327</th>
      <td>208016</td>
      <td>449814</td>
      <td>898</td>
      <td>983</td>
      <td>7996.0</td>
      <td>1110</td>
      <td>0</td>
    </tr>
    <tr>
      <th>54925328</th>
      <td>208016</td>
      <td>634856</td>
      <td>898</td>
      <td>1346</td>
      <td>7996.0</td>
      <td>1110</td>
      <td>0</td>
    </tr>
    <tr>
      <th>54925329</th>
      <td>208016</td>
      <td>272094</td>
      <td>898</td>
      <td>1346</td>
      <td>7996.0</td>
      <td>1111</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>54925330 rows Ã— 7 columns</p>

```python
user_log["user_id"].nunique()
```


    424170


```python
user_log.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 54925330 entries, 0 to 54925329
    Data columns (total 7 columns):
     #   Column       Dtype  
    ---  ------       -----  
     0   user_id      int32  
     1   item_id      int32  
     2   cat_id       int16  
     3   seller_id    int16  
     4   brand_id     float16
     5   time_stamp   int16  
     6   action_type  int8   
    dtypes: float16(1), int16(3), int32(2), int8(1)
    memory usage: 890.5 MB


## æµ‹è¯•é›†ä¿¡æ¯è¡¨


```python
test_data = reduce_mem(pd.read_csv("./data/data_format1/test_format1.csv"))
test_data
```

    -- Mem. usage decreased to  3.49 Mb (41.7% reduction),time spend:0.00 min

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>merchant_id</th>
      <th>prob</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>163968</td>
      <td>4605</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>360576</td>
      <td>1581</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>98688</td>
      <td>1964</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>98688</td>
      <td>3645</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>295296</td>
      <td>3361</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>261472</th>
      <td>228479</td>
      <td>3111</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>261473</th>
      <td>97919</td>
      <td>2341</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>261474</th>
      <td>97919</td>
      <td>3971</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>261475</th>
      <td>32639</td>
      <td>3536</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>261476</th>
      <td>32639</td>
      <td>3319</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>261477 rows Ã— 3 columns</p>



```python
test_data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 261477 entries, 0 to 261476
    Data columns (total 3 columns):
     #   Column       Non-Null Count   Dtype  
    ---  ------       --------------   -----  
     0   user_id      261477 non-null  int32  
     1   merchant_id  261477 non-null  int16  
     2   prob         0 non-null       float64
    dtypes: float64(1), int16(1), int32(1)
    memory usage: 3.5 MB


## ç¼ºå¤±å€¼


```python
# user_log ç”¨æˆ·æ—¥å¿—è¡¨
Total = user_log.isnull().sum().sort_values(ascending=False)
percent = (user_log.isnull().sum()/user_log.isnull().count()).sort_values(ascending=False)*100
missing_data = pd.concat([Total, percent], axis=1, keys=["Total", "Percent"])
missing_data
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Total</th>
      <th>Percent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>brand_id</th>
      <td>91015</td>
      <td>0.165707</td>
    </tr>
    <tr>
      <th>user_id</th>
      <td>0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>item_id</th>
      <td>0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>cat_id</th>
      <td>0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>seller_id</th>
      <td>0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>time_stamp</th>
      <td>0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>action_type</th>
      <td>0</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
ç»“è®ºï¼šç”¨æˆ·æ—¥å¿—è¡¨ä¸­çš„ç‰¹å¾ä¿¡æ¯ç¼ºå¤±æ¯”ä¾‹è¾ƒå°ï¼Œä¸”åªå‡ºç°åœ¨å“ç‰Œä¸€æ ä¸­ï¼Œå¯ä»¥åˆ é™¤ã€‚


```python
# user_info ç”¨æˆ·ä¿¡æ¯è¡¨
Total = user_info.isnull().sum().sort_values(ascending=False)
percent = (user_info.isnull().sum()/user_info.isnull().count()).sort_values(ascending=False)*100
missing_data = pd.concat([Total, percent], axis=1, keys=["Total", "Percent"])
missing_data
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Total</th>
      <th>Percent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>gender</th>
      <td>6436</td>
      <td>1.517316</td>
    </tr>
    <tr>
      <th>age_range</th>
      <td>2217</td>
      <td>0.522668</td>
    </tr>
    <tr>
      <th>user_id</th>
      <td>0</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
ç»“è®ºï¼šç”¨æˆ·ä¿¡æ¯è¡¨ä¸­ï¼Œç”¨æˆ·æ€§åˆ«å’Œå¹´é¾„ç¼ºå¤±ï¼Œè€ƒè™‘æ­¤ç‰¹å¾ä¸ºç±»åˆ«ç‰¹å¾ï¼Œå¯ä»¥ä½¿ç”¨ä¼—æ•°å¡«è¡¥, æ³¨æ„ç¼ºå¤±å€¼ä¸æ­¢ä¸ºNULLã€‚

### å¹´é¾„ç¼ºå¤±


```python
# å¹´é¾„å­—æ®µæ•°æ®å–å€¼æƒ…å†µ
user_info["age_range"].unique()
```


    array([ 6.,  5.,  4.,  7.,  3.,  0.,  8.,  2., nan,  1.], dtype=float16)


```python
# å¹´é¾„ä¸ºé›¶æˆ–ä¸ºç©ºä¸ºç¼ºå¤±å€¼ï¼Œç¼ºå¤±æ¡ç›®ä¸º95131æ¡
user_info[(user_info["age_range"] == 0) | (user_info["age_range"].isna())].count()
```


    user_id      95131
    age_range    92914
    gender       90664
    dtype: int64


```python
# ä¸åŒå¹´é¾„æ®µçš„ç¼ºå¤±ç”¨æˆ·æ•°é‡ï¼Œä¸ç»Ÿè®¡ç©ºå€¼
user_info.groupby("age_range")[["user_id"]].count()
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
    </tr>
    <tr>
      <th>age_range</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0.0</th>
      <td>92914</td>
    </tr>
    <tr>
      <th>1.0</th>
      <td>24</td>
    </tr>
    <tr>
      <th>2.0</th>
      <td>52871</td>
    </tr>
    <tr>
      <th>3.0</th>
      <td>111654</td>
    </tr>
    <tr>
      <th>4.0</th>
      <td>79991</td>
    </tr>
    <tr>
      <th>5.0</th>
      <td>40777</td>
    </tr>
    <tr>
      <th>6.0</th>
      <td>35464</td>
    </tr>
    <tr>
      <th>7.0</th>
      <td>6992</td>
    </tr>
    <tr>
      <th>8.0</th>
      <td>1266</td>
    </tr>
  </tbody>
</table>
### æ€§åˆ«ç¼ºå¤±


```python
# æŸ¥çœ‹æ€§åˆ«å–å€¼èŒƒå›´
user_info["gender"].unique()
```


    array([ 1.,  0.,  2., nan], dtype=float16)


```python
# ç»Ÿè®¡æ€§åˆ«ç¼ºå¤±æƒ…å†µ
user_info[(user_info["gender"].isna()) | (user_info["gender"] == 2)].count()
```


    user_id      16862
    age_range    14664
    gender       10426
    dtype: int64

### ç»Ÿè®¡ç”¨æˆ·åªæœ‰ä¸€ä¸ªç¼ºå¤±å€¼


```python
# æ³¨:countåªç»Ÿè®¡éNançš„å€¼ï¼Œå› æ­¤åœ¨user_idçš„æ•°é‡èƒ½å¤Ÿè¡¨ç¤ºçœŸå®çš„ç¼ºå¤±æ•°é‡
user_info[(user_info["gender"].isna()) | (user_info["gender"] == 2) | (user_info["age_range"] == 0) | (user_info["age_range"].isna())].count()
```


    user_id      106330
    age_range    104113
    gender        99894
    dtype: int64

## æ­£è´Ÿæ ·æœ¬ç»Ÿè®¡


```python
label_gp = train_data.groupby("label")["user_id"].count()
label_gp
```


    label
    0    244912
    1     15952
    Name: user_id, dtype: int64


```python
fig, ax = plt.subplots(1, 2, figsize=(12, 6))
train_data["label"].value_counts().plot(kind="pie"
                                        , ax=ax[0]
                                        , shadow=True
                                        , explode=[0, 0.1]
                                        , autopct="%1.1f%%"
                                       )

sns.countplot(x="label", data=train_data, ax=ax[1])
```


![png](./imgs/output_37_1.png)
â€‹    


ç»“è®ºï¼šæ ·æœ¬æåº¦ä¸å¹³è¡¡ï¼Œä½¿ç”¨è´Ÿé‡‡æ ·æˆ–è¿‡é‡‡æ ·æŠ€æœ¯è°ƒæ•´æ•°æ®ä¸å¹³è¡¡çš„æƒ…å†µã€‚  
[çŸ¥è¯†ç‚¹: countplot](https://www.cnblogs.com/cymx66688/p/10536403.html)

## æ¢ç´¢å½±å“å¤è´­çš„å„ç§å› ç´ 

### åˆ†æä¸åŒåº—é“ºä¸å¤è´­çš„å…³ç³»


```python
train_data_merchant = train_data.copy()
top5_idx = train_data_merchant.merchant_id.value_counts().head().index.tolist()
# å¢åŠ ä¸€åˆ—ç”¨äºæ ‡è®°Topå•†æˆ·å’ŒéTopå•†æˆ·ï¼Œä¾¿äºç»Ÿè®¡å…¶å¤è´­æƒ…å†µ
train_data_merchant["Top5"] = train_data_merchant["merchant_id"].map(lambda x: 1 if x in top5_idx else 0)
train_data_merchant = train_data_merchant[train_data_merchant.Top5 == 1]

sns.countplot(x="merchant_id", hue="label", data=train_data_merchant)
```


![png](./imgs/output_41_1.png)


ç»“è®ºï¼šä¸åŒå•†é“ºå¤è´­æƒ…å†µå¤§ä¸ç›¸åŒï¼Œå•†é“ºå¤è´­ç‡è¾ƒä½ã€‚

### æŸ¥çœ‹åº—é“ºçš„å¤è´­åˆ†å¸ƒ


```python
merchant_repeat_buy = [rate for rate in train_data.groupby("merchant_id")["label"].mean() if rate <= 1 and rate >0]
plt.figure(figsize=(8, 4))

ax1 = plt.subplot(1, 2, 1)
sns.distplot(merchant_repeat_buy, fit=scipy.stats.norm)

ax2 = plt.subplot(1, 2, 2)
res = scipy.stats.probplot(merchant_repeat_buy, plot=plt)
```


![png](./imgs/output_44_0.png)
â€‹    


ç»“è®ºï¼šç”¨æˆ·åº—é“ºå¤è´­ç‡åˆ†å¸ƒåœ¨0.15å·¦å³ï¼Œç”¨æˆ·å¤è´­ç‡è¾ƒä½ï¼Œä¸”ä¸åŒåº—é“ºå…·æœ‰ä¸åŒçš„å¤è´­ç‡ã€‚ï¼ˆæ•°æ®åˆ†å¸ƒå±äºå³åï¼‰

### æŸ¥çœ‹ç”¨æˆ·çš„å¤è´­åˆ†å¸ƒ


```python
user_repeat_buy = [rate for rate in train_data.groupby("user_id")["label"].mean() if rate <= 1 and rate >0]

plt.figure(figsize=(8, 4))
ax1 = plt.subplot(1, 2, 1)
sns.distplot(user_repeat_buy, fit=scipy.stats.norm)

ax2 = plt.subplot(1, 2, 2)
res = scipy.stats.probplot(user_repeat_buy, plot=plt)
```


![png](./imgs/output_47_0.png)


ç»“è®ºï¼šè¿‘å…­ä¸ªæœˆçš„ç”¨æˆ·ä¸»è¦é›†ä¸­åœ¨ä¸€æ¬¡è´­ä¹°ä¸ºä¸»ï¼Œè¾ƒå°‘å‡ºç°é‡å¤è´­ä¹°çš„æƒ…å†µã€‚

### å¯¹ç”¨æˆ·æ€§åˆ«çš„åˆ†æ


```python
train_data_user_info = train_data.merge(user_info, on=["user_id"], how="left")

plt.figure(figsize=(6, 4))
plt.title("Gender VS Label")
ax = sns.countplot(x="gender", hue="label", data=train_data_user_info)
for p in ax.patches:
    hight = p.get_height()
```


![png](./imgs/output_50_0.png)

```python
repeat_buy = [rate for rate in train_data_user_info.groupby("gender")["label"].mean() if rate <= 1 and rate >0]

plt.figure(figsize=(8, 4))
ax1 = plt.subplot(1, 2, 1)
sns.distplot(repeat_buy, fit=scipy.stats.norm)

ax2 = plt.subplot(1, 2, 2)
res = scipy.stats.probplot(repeat_buy, plot=plt)
```


![png](./imgs/output_51_0.png)


ç»“è®ºï¼šç”·å¥³å¤è´­æƒ…å†µå‘ˆç°å·®å¼‚æ€§ï¼Œå¥³æ€§è´­ä¹°æƒ…å†µè¿œé«˜äºç”·æ€§ã€‚

### å¯¹ç”¨æˆ·å¹´é¾„åˆ†æ


```python
plt.figure(figsize=(5, 4))
plt.title("Age VS Label")
res = sns.countplot(x="age_range", hue="label", data=train_data_user_info)
```


![png](./imgs/output_54_0.png)

```python
repeat_buy = [rate for rate in train_data_user_info.groupby("age_range")["label"].mean() if rate <= 1 and rate >0]

plt.figure(figsize=(8, 4))
ax1 = plt.subplot(1, 2, 1)
sns.distplot(repeat_buy, fit=scipy.stats.norm)

ax2 = plt.subplot(1, 2, 2)
res = scipy.stats.probplot(repeat_buy, plot=plt)
```


![png](./imgs/output_55_0.png)


ç»“è®ºï¼šç”¨æˆ·åœ¨ä¸åŒçš„å¹´é¾„é˜¶æ®µå¤è´­æƒ…å†µæœ‰å·®å¼‚ï¼Œå¹´é¾„é‡ç‚¹åˆ†å¸ƒåœ¨25~34ä¹‹é—´çš„ç”¨æˆ·ã€‚




## éšå«ç‰¹å¾æŒ–æ˜

### åµŒå…¥ç‰¹å¾


```python
# import gensim
```


```python
# sentences = all_data_test["seller_path"].apply(lambda x: x.split(" "))
# model = gensim.models.Word2Vec(sentences, size=100, window=5, min_count=5, workers=4)
```


```python
# # æ±‚è§£æ¯ä¸€ä¸ªç”¨æˆ·çš„å–œæ¬¢å•†å“çš„åµŒå…¥ç‰¹å¾çš„å¹³å‡å€¼
# def mean_w2v_(x, model, size=100):
#     """åŠ å’Œæ±‚å¹³å‡"""
    
#     try:
#         i = 0
#         for word in x.split(" "):
#             if word in model.wv.vocab:
#                 i += 1
#                 if i == 1:
#                     vec = np.zeros(size)
#                 vec += model.wv[word]
#         return vec/i
#     except:
#         return np.zeros(size)
    
# def get_mean_w2v(df_data, columns, model, size):
#     """è·å–æ‰€æœ‰ç”¨æˆ·çš„å¹³å‡å‘é‡"""
    
#     data_array = []
#     for index, data in df_data.iterrows():
#         w2v = mean_w2v_(data[columns], model, size)
#         data_array.append(w2v)
        
#     return pd.DataFrame(data_array)
```


```python
# # è·å–embeddingå‘é‡
# df_emmbedding = get_mean_w2v(all_data_test, "seller_path", model, 100)
# df_emmbedding.columns = ["embedding_" + str(i) for i in df_emmbedding.columns]
# df_emmbedding
```


```python
# åˆå¹¶åµŒå…¥ç‰¹å¾
# all_data_test = pd.concat([all_data_test, df_emmbedding], axis=1)
```


```python
all_data_test.to_csv("./data/all_data_test.csv", index=False)
```



